{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "name": "youtube_detector..ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avalenciacu/VALENCIA-ALEXIS-s-y-s/blob/main/youtube_detector_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmaPHWwtvLHa"
      },
      "outputs": [],
      "source": [
        "#cargar datos desde drive acceso libre\n",
        "#1UVHl8wyAafw1kgvke9IMi7fwUNv8ZswA\n",
        "FILEID = \"18Ul8ZQSXMWoeoNrmb5fD1vYQ9vU5bxGA\" #\"1DxI5wQpqEWksw2BqJnG7n0IgNQ_xByX-\"\n",
        "\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O  canciones.xlsx && rm -rf /tmp/cookies.txt\n",
        "#!unzip -o codigos.zip\n",
        "!dir"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "file_ = 'canciones.xlsx'#leer archivo xlsx con link, band, type\n",
        "X  = pd.read_excel(file_)\n",
        "X#imprimir filas iniciales"
      ],
      "metadata": {
        "id": "NF9zfZdPv7JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instalar librerias necesarias para descargar audios youtube\n",
        "!python3 -m pip install --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
        "!pip install soundfile\n",
        "\n",
        "# Paquete de carga de cookies para el control anti-bots captcha\n",
        "!pip install browser-cookie3\n",
        "\n",
        "import os\n",
        "import yt_dlp as youtube_dl\n",
        "import browser_cookie3\n",
        "\n",
        "try:\n",
        "    cookies = browser_cookie3.firefox()\n",
        "except:\n",
        "    print(\"No se pueden descargar cookies desde firefox. Intentando Chrome...\")\n",
        "    try:\n",
        "        cookies = browser_cookie3.chrome()\n",
        "    except:\n",
        "        print(\"No se pueden descargar cookies desde Chrome. Por favor asegúrate de estar logueado en Youtube desde tu navegador.\")\n",
        "        cookies = None\n",
        "\n",
        "#funcion para descargar mp3 desde youtube\n",
        "def download_ytvid_as_mp3(video_url,name):\n",
        "    #video_url = input(\"enter url of youtube video:\")\n",
        "    options={\n",
        "        'format':'bestaudio/best',\n",
        "        'keepvideo':False,\n",
        "        'outtmpl':f'{name}.mp3',\n",
        "    }\n",
        "    if cookies:\n",
        "        options['cookiefile'] = None\n",
        "        options['cookiejar'] = cookies;\n",
        "\n",
        "    with youtube_dl.YoutubeDL(options) as ydl:\n",
        "        try:\n",
        "            video_info = ydl.extract_info(video_url, download=False)\n",
        "            ydl.download([video_info['webpage_url']])\n",
        "            print(\"Download complete... {}\".format(filename))\n",
        "        except Exception as e:\n",
        "            print(f\"Error descargando {video_url}: {e}\")"
      ],
      "metadata": {
        "id": "-0GnJhn9wYpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "#crear carpeta con resultados\n",
        "try:\n",
        "  os.mkdir('results')\n",
        "except:\n",
        "  print(\"Carpeta results ya existe\")\n",
        "\n",
        "#recorrer excel con videos\n",
        "N, P = X.shape\n",
        "Ns = N * 5 #cantidad de segmentos por cancion\n",
        "\n",
        "for n in range(N):\n",
        "    print(f\"video {n+1} de {N}\")\n",
        "    print(f\"link: {X.loc[n,'link']}\\n\")\n",
        "    print(f\"band: {X.loc[n,'band']}\\n\")\n",
        "    print(f\"type: {X.loc[n,'type']}\\n\")\n",
        "    #ruta video n-th\n",
        "    name_ = 'results/'+X.loc[n,'band']+\"_\"+str(n)+\"_\"+str(X.loc[n,'type_num']) # #video+nombre+tipo de genero musical\n",
        "    #descargar mp3 desde youtube\n",
        "    try: # Added try block to catch download errors\n",
        "        download_ytvid_as_mp3(X.loc[n,'link'],name_)\n",
        "        #convertir a .wav\n",
        "        subprocess.call(['ffmpeg','-y', '-i', name_+'.mp3',\n",
        "                       name_+'.wav'])\n",
        "    except youtube_dl.utils.DownloadError as e: # Catch the specific DownloadError\n",
        "        print(f\"Skipping video {X.loc[n,'link']} due to download error: {e}\") # Print a message and skip"
      ],
      "metadata": {
        "id": "8q0Xv9BcwzeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cargar .wavs y partir audios\n",
        "#lista archivos .wav\n",
        "path = 'results/'\n",
        "wav_files = [f for f in os.listdir(path) if f.endswith('.wav')]\n",
        "wav_files"
      ],
      "metadata": {
        "id": "gX5bdp-7w--s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import soundfile as sf # para instalar pip install soundfile\n",
        "from scipy.signal import resample_poly\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#leer archivos y crear np.array audios\n",
        "fs = 48000\n",
        "tl = np.array([30,40,50,60,70,80]) #puntos lectura\n",
        "ts = 5 #t segmento\n",
        "# The total number of samples for each segment at the target fs\n",
        "segment_length_fs = int(ts * fs)\n",
        "Ns = len(wav_files)*len(tl) #cantidad segmentos\n",
        "# x_t should be initialized with the shape corresponding to the target fs\n",
        "x_t = np.zeros((Ns, segment_length_fs, 2)) #Ns segmentos, cantidad de muestras, 2 canales (stereo)\n",
        "label = np.zeros((Ns,1)) #vector tipo de genero\n",
        "type_c = X['type'].unique()\n",
        "name_c = []\n",
        "#leer archivos wav\n",
        "i = 0\n",
        "for name in wav_files:#lectura audio .wav\n",
        "    x, fs_i = sf.read(path+name)\n",
        "    # Ensure x is at least 2D (for stereo)\n",
        "\n",
        "    if x.ndim == 1:\n",
        "        x = np.expand_dims(x, axis=1) # Add a channel dimension if mono\n",
        "    if x.shape[1] == 1: # If still mono after expand_dims\n",
        "        x = np.repeat(x, 2, axis=1) # Convert mono to stereo by repeating the channel\n",
        "\n",
        "    # Check if the audio file has enough data for the requested segments\n",
        "    if len(x) < int(fs_i * (tl[-1] + ts)):\n",
        "        print(f\"Warning: File {name} is too short for all requested segments. Skipping some segments.\")\n",
        "        valid_tl = tl[tl + ts <= len(x)/fs_i]\n",
        "    else:\n",
        "        valid_tl = tl\n",
        "\n",
        "    for ti in valid_tl: #segmentos de tiempo\n",
        "        print(name,'x',x.shape,'fs actual:',fs_i)\n",
        "\n",
        "        # Slice based on the original sampling rate fs_i\n",
        "        start_sample = int(fs_i * ti)\n",
        "        end_sample = int(fs_i * (ti + ts))\n",
        "        xc = x[start_sample:end_sample, :]\n",
        "\n",
        "        # Check if the sliced segment has enough data for resampling\n",
        "        # This can happen if the calculated end_sample exceeds the actual audio length\n",
        "        if xc.shape[0] < int(ts * fs_i):\n",
        "            print(f\"Warning: Segment from {ti}s to {ti+ts}s in {name} is shorter than expected. Skipping.\")\n",
        "            continue # Skip this segment\n",
        "\n",
        "        if fs_i != fs:\n",
        "            # Resample using resample_poly\n",
        "            # The output length of resample_poly is len(xc) * up / down\n",
        "            # We want the resampled length to be exactly segment_length_fs\n",
        "            # So we need to calculate up and down such that len(xc) * up / down = segment_length_fs\n",
        "            # Or simply use the desired number of samples directly if supported by resample_poly\n",
        "            # resample_poly can take 'nyq' or 'kaiser_beta' arguments for filter design,\n",
        "            # but for simple resampling to a target number of points, a direct approach is needed.\n",
        "            # A simpler resample function might be better, or calculate up/down differently.\n",
        "\n",
        "            # Let's use a method that targets the desired number of samples directly.\n",
        "            # scipy.signal.resample can do this, but it uses FFT and might not be ideal.\n",
        "            # Let's adjust the resampling calculation with resample_poly to ensure the correct output size.\n",
        "            # Target output size is segment_length_fs.\n",
        "            # Current size is xc.shape[0].\n",
        "            # We want xc.shape[0] * (up / down) = segment_length_fs\n",
        "            # Let's find up and down that approximate fs/fs_i\n",
        "            # A more robust way is to use a library that handles resampling to a specific length.\n",
        "            # For now, let's ensure the resampled array is truncated or padded if necessary,\n",
        "            # although it's better to get the resampling right.\n",
        "\n",
        "            # A common approach for arbitrary resampling is\n",
        "            # import librosa\n",
        "            # xc_resampled = librosa.resample(xc, orig_sr=fs_i, target_sr=fs)\n",
        "            # However, this outputs a 1D array for mono. Need to handle stereo.\n",
        "\n",
        "            # Let's stick with resample_poly but ensure the output is the correct size.\n",
        "            # If resampling makes it slightly longer or shorter, we'll handle it.\n",
        "            gcd_val = np.gcd(fs, fs_i)\n",
        "            up_val = fs // gcd_val\n",
        "            down_val = fs_i // gcd_val\n",
        "\n",
        "            # Resample each channel separately\n",
        "            xc_resampled_ch1 = resample_poly(xc[:, 0], up=up_val, down=down_val)\n",
        "            xc_resampled_ch2 = resample_poly(xc[:, 1], up=up_val, down=down_val)\n",
        "\n",
        "            # Combine channels\n",
        "            xc_resampled = np.stack((xc_resampled_ch1, xc_resampled_ch2), axis=-1)\n",
        "\n",
        "            # Ensure the resampled segment has the target length (segment_length_fs)\n",
        "            if xc_resampled.shape[0] > segment_length_fs:\n",
        "                xc_resampled = xc_resampled[:segment_length_fs, :]\n",
        "            elif xc_resampled.shape[0] < segment_length_fs:\n",
        "                # Pad with zeros if shorter\n",
        "                padding = np.zeros((segment_length_fs - xc_resampled.shape[0], 2))\n",
        "                xc_resampled = np.vstack((xc_resampled, padding))\n",
        "\n",
        "            xc = xc_resampled # Use the resampled array\n",
        "            print(f\"Resampled to shape: {xc.shape}\")\n",
        "\n",
        "        # Now xc should have the shape (segment_length_fs, 2) which is (240000, 2)\n",
        "        if xc.shape[0] != segment_length_fs:\n",
        "             print(f\"Error: Resampled segment has incorrect length {xc.shape[0]}. Expected {segment_length_fs}. Skipping.\")\n",
        "             continue # Skip this segment if resampling failed to produce correct length\n",
        "\n",
        "\n",
        "        x_t[i] = xc\n",
        "        # The label indexing seems to assume the order of wav_files matches the order in X\n",
        "        # and the type_num is the last digit before '.wav' and is 1 or 2.\n",
        "        # This might be fragile. Consider using the 'type_num' column from X directly\n",
        "        # based on the filename or a mapping.\n",
        "        # For now, sticking to the original logic for the label.\n",
        "        try:\n",
        "             # Extract type_num from the filename\n",
        "             parts = name.split('_')\n",
        "             type_num_str = parts[-1].split('.')[0]\n",
        "             label[i] = int(type_num_str)\n",
        "        except (IndexError, ValueError):\n",
        "             print(f\"Warning: Could not extract type_num from filename {name}. Setting label to 0.\")\n",
        "             label[i] = 0 # Assign a default or error label\n",
        "\n",
        "        # The name_c logic also seems to assume the filename format.\n",
        "        # Sticking to original logic.\n",
        "        name_c += [name[:-4]] # Remove '.wav' from the end\n",
        "\n",
        "\n",
        "        print(f\"{i} lectura: {name}; segundo {ti}:{ti+ts}; tipo música: {type_c[int(label[i])-1]}\")\n",
        "        i+=1\n",
        "\n",
        "# After the loop, if some segments were skipped, the actual number of populated segments in x_t and label\n",
        "# might be less than Ns. We should truncate these arrays to the actual number of populated segments.\n",
        "# Ns was calculated based on the initial assumption of processing all segments.\n",
        "# Let's re-calculate the effective Ns (number of processed segments).\n",
        "effective_Ns = i\n",
        "x_t = x_t[:effective_Ns]\n",
        "label = label[:effective_Ns]\n",
        "name_c = name_c[:effective_Ns]\n",
        "\n",
        "x_t.shape"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "F2iqEiiD7Lkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio #reproducir segmento\n",
        "i = 0\n",
        "Audio(x_t[i].T,rate=fs)"
      ],
      "metadata": {
        "id": "YM3ltcs6zOHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculo de fourier\n",
        "vf = np.fft.rfftfreq(x_t.shape[1],1/fs) #calculo vector de frecuencias\n",
        "Xw = np.fft.rfft(x_t,axis=1).mean(axis=-1) #transformada rapida de Fourier para señal Real a lo largo del tiempo (axis=1) y se promedian los dos canales\n",
        "Xw.shape"
      ],
      "metadata": {
        "id": "qcd1pUoz2KM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#grafica tiempo y fourier\n",
        "plt.plot(np.arange(0,ts,1/fs),x_t.mean(axis=-1).T) #se promedian los dos canales stereo\n",
        "plt.xlabel('t[s]')\n",
        "plt.ylabel('x(t)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NiacFvIx4vpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(vf,abs(Xw).T)\n",
        "plt.xlabel('f[Hz]')\n",
        "plt.ylabel('|X(f)|')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "roZkalWc5cqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#se normalizan espectros entre 0 y 1 para evitar inconsistencias por ampliltudes máximas\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sca = MinMaxScaler()\n",
        "Xw_ = sca.fit_transform(abs(Xw).T).T\n",
        "\n",
        "plt.plot(vf,Xw_.T)\n",
        "plt.xlabel('f[Hz]')\n",
        "plt.ylabel('|X(f)|')\n",
        "plt.show()\n",
        "\n",
        "#en dB\n",
        "plt.plot(vf,(20*np.log10(Xw_+1e-10)).T) # se suma 1e-10 para evitar discontinuidad del log\n",
        "plt.xlabel('f[Hz]')\n",
        "plt.ylabel('|X(f)| dB')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DR4Tw83c6b-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota**: Generalmente el espectro se presenta en [decibeles [dB]](https://es.wikipedia.org/wiki/Decibelio)"
      ],
      "metadata": {
        "id": "AXaYxHDVQj1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualización de los datos en 2D"
      ],
      "metadata": {
        "id": "zgPMJDn8iQiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from umap import UMAP\n",
        "#visualización de datos\n",
        "n_neighbors = int(2*np.sqrt(Xw_.shape[0]))\n",
        "sca_ = MinMaxScaler()\n",
        "\n",
        "red_ = UMAP(n_components=2,n_neighbors=n_neighbors)\n",
        "X_2D = sca_.fit_transform(red_.fit_transform(Xw_))"
      ],
      "metadata": {
        "id": "UZGVCWRk1eAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#graficar separabilidad 2D\n",
        "plt.scatter(X_2D[:,0],X_2D[:,1],c=label)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "color_ = [\"b\",\"y\"]\n",
        "#nombre cancion\n",
        "plt.scatter(X_2D[:,0],X_2D[:,1],c=label,s=1)\n",
        "for i, tex in enumerate(name_c):\n",
        "    #print(f\"{i} {tex}\")\n",
        "    plt.text(X_2D[i,0]*1.025,X_2D[i,1]*1.025, tex[:-2]+\"_\"+str(i), fontsize=6,color=color_[int(label[i]-1)])\n",
        "\n",
        "plt.xlim([-0.1,1.1])\n",
        "plt.ylim([-0.1,1.1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A2Tmfe-57ZEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reproducir audio\n",
        "i = 1\n",
        "Audio(x_t[i].T,rate=fs)"
      ],
      "metadata": {
        "id": "fubfCcH5CHzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicción del género musical sobre espectro de Fourier"
      ],
      "metadata": {
        "id": "7f1dbQS2i_az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Crear una instancia del clasificador RandomForest\n",
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Realizar la validación cruzada\n",
        "# Xw_ son tus características y label son tus etiquetas\n",
        "# cv define el número folds para la validación cruzada\n",
        "scores = cross_val_score(model, Xw_, label.ravel(), cv=5,scoring='accuracy')\n",
        "\n",
        "# Imprimir los resultados de la validación cruzada\n",
        "print(\"Acierto para cada Fold:\", scores)\n",
        "print(\"Acierto promedio:\", scores.mean())\n",
        "print(\"Desviación estándar del Acierto:\", scores.std())\n",
        "\n",
        "#entrenar modelo para predecir nuevas canciones\n",
        "model.fit(Xw_, label.ravel())"
      ],
      "metadata": {
        "id": "XgvontVai8Qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "#guardar modelo\n",
        "try:\n",
        "  os.mkdir('modelo')\n",
        "except:\n",
        "  print(\"Carpeta modelo ya existe\")\n",
        "\n",
        "filename_ = 'modelo/reggaeton_vs_metal'\n",
        "model_ ={'Xw_':Xw_, 'label' : label, 'name_c' : name_c, 'vf':vf,'fs':fs, 'modelo':model,'type':X['type'].unique()}\n",
        "joblib.dump(model_,filename_+\".pkl\")\n"
      ],
      "metadata": {
        "id": "JFDhqdxH79cI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#descargar modelo\n",
        "#guardar resultados\n",
        "from google.colab import files\n",
        "from datetime import date, datetime\n",
        "import shutil\n",
        "#guardar resultados\n",
        "namefile = str(datetime.now().strftime(\"%Y_%m_%d_%H_%M_%d\"))+'modelo'\n",
        "shutil.make_archive(namefile, 'zip', 'modelo')\n",
        "files.download(namefile+'.zip')\n",
        "\n",
        "#el archivo .zip puede cargarse en drive y utilizarse en otro cuaderno para detectar género musical de nuevos segmentos"
      ],
      "metadata": {
        "id": "7zWJ8LNQBjNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Para una nueva canción"
      ],
      "metadata": {
        "id": "Wh19I5HGlwyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cargar modelo\n",
        "my_model_loaded = joblib.load(filename_+\".pkl\")\n",
        "my_model_loaded.keys()"
      ],
      "metadata": {
        "id": "LRJ7txqCA1bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluar para un segmento en fft normalizado\n",
        "\n",
        "pred_ = my_model_loaded['modelo'].predict(Xw_[0].reshape(1,-1))[0]\n",
        "print('Etiqueta estimada: ',my_model_loaded['type'][int(pred_-1)])\n",
        "print('Etiqueta orignal: ',my_model_loaded['type'][int(my_model_loaded['label'][0][0])-1])"
      ],
      "metadata": {
        "id": "k5ykNmZem4ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EDXDlpnfreE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ESTREAMLIT**"
      ],
      "metadata": {
        "id": "uFyMNZOLg9PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit joblib yt-dlp soundfile scipy umap-learn pandas numpy matplotlib"
      ],
      "metadata": {
        "id": "tTtoAZ2EhFie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1858ea3"
      },
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import joblib\n",
        "import yt_dlp as youtube_dl\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from scipy.signal import resample_poly\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from umap import UMAP # Although UMAP is not strictly needed for the prediction itself, it was used in the original notebook for visualization and might be useful later or for debugging.\n",
        "import subprocess\n",
        "import time # Import time for potential delays\n",
        "\n",
        "# Load the trained model and related data\n",
        "# Make sure the 'modelo' directory and 'reggaeton_vs_metal.pkl' file exist\n",
        "# in the same directory where you run this script, or provide the correct path.\n",
        "try:\n",
        "    my_model_loaded = joblib.load('modelo/reggaeton_vs_metal.pkl')\n",
        "    model = my_model_loaded['modelo']\n",
        "    vf = my_model_loaded['vf']\n",
        "    fs = my_model_loaded['fs']\n",
        "    type_c = my_model_loaded['type']\n",
        "    # Xw_ and label are not strictly needed for prediction on a new sample,\n",
        "    # but keeping them here in case they are used for visualization or other purposes later.\n",
        "    # Xw_ = my_model_loaded['Xw_']\n",
        "    # label = my_model_loaded['label']\n",
        "    # st.success(\"Modelo cargado exitosamente.\") # Avoid Streamlit calls outside st functions\n",
        "except FileNotFoundError:\n",
        "    # st.error(\"Error: Archivo del modelo 'modelo/reggaeton_vs_metal.pkl' no encontrado. Asegúrate de que la carpeta 'modelo' y el archivo .pkl estén en la ubicación correcta.\")\n",
        "    st.stop() # Stop the app if the model cannot be loaded.\n",
        "except Exception as e:\n",
        "    # st.error(f\"Error al cargar el modelo: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "\n",
        "# Define the audio processing parameters\n",
        "ts = 5  # segment time in seconds\n",
        "segment_length_fs = int(ts * fs)\n",
        "\n",
        "# Function to download audio as mp3 from YouTube (adapted from your original code)\n",
        "def download_ytvid_as_mp3_streamlit(video_url, output_path):\n",
        "    options={\n",
        "        'format':'bestaudio/best',\n",
        "        'keepvideo':False,\n",
        "        'outtmpl':f'{output_path}.mp3',\n",
        "        'nocheckcertificate':True, # Added to potentially help with certificate issues\n",
        "        'no_warnings':True, # Suppress warnings\n",
        "        'quiet':True, # Suppress verbose output\n",
        "        'postprocessors': [{\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'mp3',\n",
        "        }],\n",
        "         'extract_audio': True,\n",
        "    }\n",
        "    try:\n",
        "        with youtube_dl.YoutubeDL(options) as ydl:\n",
        "            ydl.download([video_url])\n",
        "        return True, None # Return True on success\n",
        "    except Exception as e:\n",
        "        return False, e # Return False and the error on failure\n",
        "\n",
        "\n",
        "# Function to process the downloaded audio (adapted from your original code)\n",
        "def process_audio_for_prediction(audio_path, target_fs, segment_duration):\n",
        "    try:\n",
        "        x, fs_i = sf.read(audio_path)\n",
        "\n",
        "        if x.ndim == 1:\n",
        "            x = np.expand_dims(x, axis=1)\n",
        "        if x.shape[1] == 1:\n",
        "            x = np.repeat(x, 2, axis=1)\n",
        "\n",
        "        # Take a segment for analysis (e.g., from 30s to 35s as in your original notebook)\n",
        "        # You might want to make this starting point configurable or analyze multiple segments\n",
        "        start_time = 30 # seconds\n",
        "        start_sample = int(fs_i * start_time)\n",
        "        end_sample = int(fs_i * (start_time + segment_duration))\n",
        "\n",
        "        if end_sample > len(x):\n",
        "            st.warning(f\"El audio es demasiado corto para tomar el segmento desde {start_time}s. Tomando el último segmento posible.\")\n",
        "            end_sample = len(x)\n",
        "            start_sample = int(end_sample - fs_i * segment_duration)\n",
        "            if start_sample < 0:\n",
        "                 start_sample = 0 # Ensure start_sample is not negative\n",
        "                 st.warning(\"El audio es demasiado corto incluso para un segmento completo. Analizando el audio disponible.\")\n",
        "\n",
        "        xc = x[start_sample:end_sample, :]\n",
        "\n",
        "        if fs_i != target_fs:\n",
        "            # Resample using resample_poly\n",
        "            gcd_val = np.gcd(target_fs, fs_i)\n",
        "            up_val = target_fs // gcd_val\n",
        "            down_val = fs_i // gcd_val\n",
        "\n",
        "            # Ensure that the resampled signal has the target length\n",
        "            target_length = int(segment_duration * target_fs)\n",
        "            xc_resampled_ch1 = resample_poly(xc[:, 0], up=up_val, down=down_val, N=target_length)\n",
        "            xc_resampled_ch2 = resample_poly(xc[:, 1], up=up_val, down=down_val, N=target_length)\n",
        "\n",
        "            xc_resampled = np.stack((xc_resampled_ch1, xc_resampled_ch2), axis=-1)\n",
        "            xc = xc_resampled\n",
        "\n",
        "        # Calculate Fourier Transform\n",
        "        # Ensure the segment has the correct length before FFT\n",
        "        if xc.shape[0] != int(segment_duration * target_fs):\n",
        "             st.error(f\"Error de procesamiento: el segmento de audio no tiene la longitud esperada para FFT. Esperado: {int(segment_duration * target_fs)}, Obtenido: {xc.shape[0]}\")\n",
        "             return None, \"Longitud de segmento incorrecta después del remuestreo.\"\n",
        "\n",
        "\n",
        "        Xw = np.fft.rfft(xc, axis=0).mean(axis=-1) # FFT along time axis (axis=0), then average channels\n",
        "\n",
        "        # Normalize spectrum\n",
        "        sca = MinMaxScaler()\n",
        "        # Need to reshape for MinMaxScaler as it expects a 2D array\n",
        "        Xw_ = sca.fit_transform(np.abs(Xw).reshape(-1, 1)).T # Reshape and transpose to match original Xw_ shape\n",
        "\n",
        "        # Ensure the normalized spectrum has the correct number of features\n",
        "        expected_features = len(vf) # Use the vf from the loaded model\n",
        "        if Xw_.shape[1] != expected_features:\n",
        "             st.error(f\"Error de procesamiento: las características extraídas no tienen el tamaño esperado. Esperado: {expected_features}, Obtenido: {Xw_.shape[1]}\")\n",
        "             return None, \"Número de características extraídas incorrecto.\"\n",
        "\n",
        "        return Xw_, None\n",
        "    except Exception as e:\n",
        "        return None, e\n",
        "\n",
        "\n",
        "# Streamlit App\n",
        "st.title(\"Detector de Género Musical (Rock vs Reggaeton)\")\n",
        "\n",
        "st.write(\"Pega el enlace de un video de YouTube y el modelo intentará predecir si el género musical es Rock o Reggaeton.\")\n",
        "\n",
        "youtube_url = st.text_input(\"Enlace de YouTube:\")\n",
        "\n",
        "# Add a placeholder for status messages\n",
        "status_text = st.empty()\n",
        "\n",
        "if st.button(\"Analizar\"):\n",
        "    if youtube_url:\n",
        "        status_text.info(f\"Analizando: {youtube_url}\")\n",
        "\n",
        "        # Define a temporary file name for the downloaded audio\n",
        "        temp_audio_mp3 = \"temp_audio.mp3\"\n",
        "        temp_audio_wav = \"temp_audio.wav\"\n",
        "\n",
        "        # Clean up previous temporary files if they exist\n",
        "        if os.path.exists(temp_audio_mp3):\n",
        "            os.remove(temp_audio_mp3)\n",
        "        if os.path.exists(temp_audio_wav):\n",
        "            os.remove(temp_audio_wav)\n",
        "\n",
        "        # 1. Download the audio\n",
        "        status_text.text(\"Descargando audio...\")\n",
        "        success, error = download_ytvid_as_mp3_streamlit(youtube_url, temp_audio_mp3[:-4]) # Pass name without extension\n",
        "\n",
        "        if not success:\n",
        "            status_text.error(f\"Error al descargar el video: {error}\")\n",
        "        else:\n",
        "            status_text.success(\"Audio descargado.\")\n",
        "            status_text.text(\"Convirtiendo a WAV...\")\n",
        "            # 2. Convert to WAV\n",
        "            try:\n",
        "                # Use absolute paths for subprocess for better reliability\n",
        "                temp_audio_mp3_abs = os.path.abspath(temp_audio_mp3)\n",
        "                temp_audio_wav_abs = os.path.abspath(temp_audio_wav)\n",
        "\n",
        "                subprocess.run(['ffmpeg', '-y', '-i', temp_audio_mp3_abs, temp_audio_wav_abs],\n",
        "                               check=True, # Raise an exception if the command fails\n",
        "                               capture_output=True, # Capture stdout and stderr\n",
        "                               text=True) # Decode output as text\n",
        "\n",
        "                status_text.success(\"Conversión a WAV completada.\")\n",
        "\n",
        "                # 3. Process the audio and get features\n",
        "                status_text.text(\"Procesando audio y extrayendo características...\")\n",
        "                Xw_, error = process_audio_for_prediction(temp_audio_wav_abs, fs, ts)\n",
        "\n",
        "                if error:\n",
        "                    status_text.error(f\"Error al procesar el audio: {error}\")\n",
        "                elif Xw_ is None:\n",
        "                     status_text.error(\"Error al procesar el audio: no se pudieron extraer características.\")\n",
        "                else:\n",
        "                    status_text.success(\"Procesamiento completado.\")\n",
        "\n",
        "                    # 4. Make a prediction\n",
        "                    status_text.text(\"Realizando predicción...\")\n",
        "                    try:\n",
        "                        pred_ = model.predict(Xw_)[0]\n",
        "                        # Ensure the predicted label index is within the bounds of type_c\n",
        "                        if 0 <= int(pred_-1) < len(type_c):\n",
        "                             predicted_genre = type_c[int(pred_-1)]\n",
        "                             st.subheader(\"Resultado de la Predicción:\")\n",
        "                             st.write(f\"El género musical predicho es: **{predicted_genre}**\")\n",
        "                        else:\n",
        "                             status_text.error(f\"Error: El modelo predijo una etiqueta inesperada: {pred_}\")\n",
        "\n",
        "\n",
        "                    except Exception as e:\n",
        "                        status_text.error(f\"Error al realizar la predicción: {e}\")\n",
        "\n",
        "            except FileNotFoundError:\n",
        "                 status_text.error(\"Error: FFmpeg no encontrado. Asegúrate de que FFmpeg esté instalado y en el PATH.\")\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                 status_text.error(f\"Error durante la conversión con FFmpeg: {e.stderr}\")\n",
        "            except Exception as e:\n",
        "                status_text.error(f\"Error durante la conversión o procesamiento: {e}\")\n",
        "            finally:\n",
        "                # Clean up temporary files\n",
        "                if os.path.exists(temp_audio_mp3):\n",
        "                    os.remove(temp_audio_mp3)\n",
        "                if os.path.exists(temp_audio_wav):\n",
        "                    os.remove(temp_audio_wav)\n",
        "                status_text.text(\"Limpieza de archivos temporales completada.\")\n",
        "    else:\n",
        "        status_text.warning(\"Por favor, introduce un enlace de YouTube.\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "---\n",
        "Este detector utiliza un modelo de clasificación entrenado con espectros de Fourier de segmentos de audio.\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dbf6763"
      },
      "source": [
        "# Install ngrok\n",
        "!pip install ngrok\n",
        "\n",
        "# Run the Streamlit app in the background\n",
        "# Use nohup to allow the process to continue after the Colab cell finishes execution (though the tunnel will close)\n",
        "# Redirect output to prevent it from cluttering the Colab output\n",
        "!nohup streamlit run app.py &>/dev/null&\n",
        "\n",
        "# Allow some time for the Streamlit app to start\n",
        "import time\n",
        "time.sleep(5)\n",
        "\n",
        "# Start ngrok and capture the public URL\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill any running ngrok processes to avoid conflicts\n",
        "ngrok.kill()\n",
        "\n",
        "# Start a new ngrok tunnel to the Streamlit port (default is 8501)\n",
        "# Get the public URL\n",
        "try:\n",
        "    public_url = ngrok.connect(addr=\"8501\", proto=\"http\").public_url\n",
        "    print(f\"Tu aplicación Streamlit está disponible en: {public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al iniciar ngrok: {e}\")\n",
        "    print(\"Por favor, intenta ejecutar la celda nuevamente.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14e5f97e"
      },
      "source": [
        "He generado dos celdas de código:\n",
        "\n",
        "1.  La primera celda utiliza `%%writefile app.py` para guardar el código de la aplicación Streamlit en un archivo llamado `app.py`. He realizado algunas modificaciones al código anterior para que funcione mejor en un entorno de servidor como Streamlit (por ejemplo, usando `st.info`, `st.success`, `st.error` para los mensajes de estado en lugar de `print`). También he ajustado la función `process_audio_for_prediction` para manejar el remuestreo y la verificación de la longitud del segmento de manera más robusta.\n",
        "2.  La segunda celda instala `ngrok`, ejecuta la aplicación Streamlit en segundo plano usando `nohup` y luego utiliza `pyngrok` para crear un túnel HTTP a la aplicación Streamlit que se ejecuta en el puerto 8501 (el puerto por defecto de Streamlit).\n",
        "\n",
        "Una vez que ejecutes la segunda celda, deberías ver un mensaje que te proporciona la URL pública donde puedes acceder a tu detector de género musical.\n",
        "\n",
        "**Importante:** El túnel `ngrok` y la aplicación Streamlit se detendrán cuando la sesión de Colab termine o se desconecte el entorno de ejecución. Si quieres que la aplicación esté disponible por más tiempo, necesitarías desplegarla en un servicio de hosting dedicado para Streamlit o una plataforma en la nube.\n",
        "\n",
        "¡Espero que esto te sea útil! Ejecuta las celdas y prueba tu detector de música."
      ]
    }
  ]
}